{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d8741bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e7c4e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12cf6950760>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.config('spark.driver.host','localhost').appName('practice').getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f087e73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|    Sunny|  29|         4| 20000|\n",
      "|     Paul|  24|         3| 20000|\n",
      "|   Harsha|  21|         1| 15000|\n",
      "|  Shubham|  23|         2| 18000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "|     null|  36|      null|  null|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark = spark.read.csv('test2.csv',header=True, inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e8d487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop  null values\n",
    "\n",
    "df_spark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1feaf8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop with threshold\n",
    "\n",
    "df_spark.na.drop(thresh=3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2eb8cd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|     null| 34|        10| 38000|\n",
      "|     null| 36|      null|  null|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop with subset\n",
    "\n",
    "df_spark.na.drop(subset='age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0b885b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+\n",
      "|     Name|age|Experience|Salary|\n",
      "+---------+---+----------+------+\n",
      "|    Krish| 31|        10| 30000|\n",
      "|Sudhanshu| 30|         8| 25000|\n",
      "|    Sunny| 29|         4| 20000|\n",
      "|     Paul| 24|         3| 20000|\n",
      "|   Harsha| 21|         1| 15000|\n",
      "|  Shubham| 23|         2| 18000|\n",
      "|   Mahesh| -1|        -1| 40000|\n",
      "|  missing| 34|        10| 38000|\n",
      "|  missing| 36|        -1|    -1|\n",
      "+---------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filling missing value\n",
    "\n",
    "#df_spark.na.fill('missing').show() #  for string\n",
    "#df_spark.na.fill(-1).show() # for int\n",
    "df_spark.na.fill(-1).na.fill('missing').show() # for both\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60ddd3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
      "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
      "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
      "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
      "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
      "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
      "|   Mahesh|null|      null| 40000|         28|                 5|         40000|\n",
      "|     null|  34|        10| 38000|         34|                10|         38000|\n",
      "|     null|  36|      null|  null|         36|                 5|         25750|\n",
      "+---------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#imputer - fill null value with mean,mode,median\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=['age','Experience','Salary'], outputCols=[f'{c}_imputed' for c in ['age','Experience','Salary']]).setStrategy('mean')\n",
    "\n",
    "imputer.fit(df_spark).transform(df_spark).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1542bf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+\n",
      "|   name|age|\n",
      "+-------+---+\n",
      "|  Sunny| 29|\n",
      "|   Paul| 24|\n",
      "| Harsha| 21|\n",
      "|Shubham| 23|\n",
      "+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#filter operation\n",
    "\n",
    "df_spark.filter('salary<=20000').select(['name','age']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6e7f5438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|  Sunny| 29|         4| 20000|\n",
      "|   Paul| 24|         3| 20000|\n",
      "| Harsha| 21|         1| 15000|\n",
      "|Shubham| 23|         2| 18000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.filter( (df_spark['salary']<=20000) & (df_spark['salary']>=15000) ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4035b60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------+------+\n",
      "|     Name| age|Experience|Salary|\n",
      "+---------+----+----------+------+\n",
      "|    Krish|  31|        10| 30000|\n",
      "|Sudhanshu|  30|         8| 25000|\n",
      "|   Mahesh|null|      null| 40000|\n",
      "|     null|  34|        10| 38000|\n",
      "+---------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.filter( ~(df_spark['salary']<=20000) ).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5291fb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------------+-----------+\n",
      "|     name|sum(age)|sum(Experience)|sum(Salary)|\n",
      "+---------+--------+---------------+-----------+\n",
      "|     null|      70|             10|      38000|\n",
      "|Sudhanshu|      30|              8|      25000|\n",
      "|    Sunny|      29|              4|      20000|\n",
      "|    Krish|      31|             10|      30000|\n",
      "|   Harsha|      21|              1|      15000|\n",
      "|     Paul|      24|              3|      20000|\n",
      "|  Shubham|      23|              2|      18000|\n",
      "|   Mahesh|    null|           null|      40000|\n",
      "+---------+--------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#aggregate function\n",
    "\n",
    "\n",
    "df_spark.groupBy('name').sum().show() #avg,mean, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d839595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(Salary)|\n",
      "+-----------+\n",
      "|     206000|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.agg({'Salary': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9211feaa",
   "metadata": {},
   "source": [
    "# Pyspark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b55d53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_spark=df_spark.na.fill(-1).na.fill('missing') # fill all null values before using VectorAssembler\n",
    "df_spark=df_spark.na.drop() # or delete all row with nulls value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "20de6c67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------+-----------+\n",
      "|     Name|age|Experience|Salary|independent|\n",
      "+---------+---+----------+------+-----------+\n",
      "|    Krish| 31|        10| 30000|[31.0,10.0]|\n",
      "|Sudhanshu| 30|         8| 25000| [30.0,8.0]|\n",
      "|    Sunny| 29|         4| 20000| [29.0,4.0]|\n",
      "|     Paul| 24|         3| 20000| [24.0,3.0]|\n",
      "|   Harsha| 21|         1| 15000| [21.0,1.0]|\n",
      "|  Shubham| 23|         2| 18000| [23.0,2.0]|\n",
      "+---------+---+----------+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureAssembler = VectorAssembler(inputCols=['age','Experience'],\n",
    "                                  outputCol='independent')\n",
    "\n",
    "output=featureAssembler.transform(df_spark)\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "15d1211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|independent|Salary|\n",
      "+-----------+------+\n",
      "|[31.0,10.0]| 30000|\n",
      "| [30.0,8.0]| 25000|\n",
      "| [29.0,4.0]| 20000|\n",
      "| [24.0,3.0]| 20000|\n",
      "| [21.0,1.0]| 15000|\n",
      "| [23.0,2.0]| 18000|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized_data = output.select('independent','Salary')\n",
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "71fdf124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data, test_data = finalized_data.randomSplit([.75,.25])\n",
    "regressor = LinearRegression(featuresCol='independent',labelCol='Salary')\n",
    "regressor = regressor.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "877e8c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([109.3058, 1199.4092])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "da707ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12187.592319054227"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "11647712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------------------+\n",
      "|independent|Salary|        prediction|\n",
      "+-----------+------+------------------+\n",
      "| [24.0,3.0]| 20000| 18409.15805022155|\n",
      "|[31.0,10.0]| 30000|27570.162481536143|\n",
      "+-----------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results = regressor.evaluate(test_data)\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "115ca264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8313022304938102"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2a8158f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2010.339734121153, 4217444.237654746)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError, pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32de0641",
   "metadata": {},
   "source": [
    "# indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04ec663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12cf6950760>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparks = SparkSession.builder.config('spark.driver.host','localhost').appName('ok').getOrCreate()\n",
    "sparks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "39708593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df = sparks.read.csv('tips.csv',header=True, inferSchema=True)\n",
    "spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "13c718e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|sex_indexed|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|        1.0|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|        0.0|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|        1.0|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|        0.0|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|        1.0|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|        0.0|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|        1.0|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|        0.0|\n",
      "+----------+----+------+------+---+------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol='sex', outputCol='sex_indexed')\n",
    "df_r = indexer.fit(spark_df).transform(spark_df)\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ffa36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
